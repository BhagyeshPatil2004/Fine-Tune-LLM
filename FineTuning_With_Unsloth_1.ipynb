{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iGzYrfWz1JC",
    "outputId": "299fa89d-3ef5-496b-88ee-968109344469"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m359.3/359.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip install -q --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a quantized Llama 3.2 model using Unsloth's FastLanguageModel for efficient inference/training."
   ],
   "metadata": {
    "id": "so3TYVE20zLY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! Unsloth also supports RoPE (Rotary Positinal Embedding) scaling internally.\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit, # Will load the 4Bit Quantized Model\n",
    ")"
   ],
   "metadata": {
    "id": "QIOG2hmz0b9M",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348,
     "referenced_widgets": [
      "c58c2843648b482698ed0eeac728de72",
      "236ed6543dcb46928c9db07e18b95b5e",
      "251d908c696e4647935cc398436288ee",
      "7d8dc7b34ed64576a6f23a3e0cf315b6",
      "d1deab578d054ceb9f2634eb29330604",
      "947b052a17bf4007bc25760175baddcc",
      "07bf106d761443e5950cf8d81577ae10",
      "7841da367f1241fdb5e626a81f84496a",
      "ae809de2081b466aac23da9dd9be4a98",
      "d35aa76d9fe24439b1c1ae7ed58832d4",
      "e09a2c03f01a49c8b15e76186a1ef41a",
      "b57bae2a8a4f4abf9512c5c60f876f85",
      "1892baf670a4478d8d71c7bb9a93fd06",
      "4f3d978f611649258cfbcf0aedd81686",
      "1620607b352a4ebd88ea6d5f4a8c0bcd",
      "8a5afc06a0b3498cb8057e2f5fbfe7df",
      "d108577ebcc44551ac787df624ffab11",
      "a45b62f744af4b8f844b0d43bacf4219",
      "5870cf4254194937a89e667a517d1980",
      "872190ae58f74d568dd63dbee6ce3576",
      "a740bcbcc050415b9724beaea9a58e7d",
      "478cbb10c4a6459cbb732eeee9f1a76b",
      "e037c4882c6a4a07be2ce6fcbeaa5a57",
      "406f857c32c14a06881c1eb15183f349",
      "9369ab3fe949420f9e02ff1b976d8c0c",
      "0a8ccd8109db467183e1af5f2f692b84",
      "c353d628941043e8b42e2c7c2a7b12f8",
      "24f93ce4f50749419eb91c45bd48b14a",
      "2f9f73418d56423994f2bc6c9af31d94",
      "ef6f28b7506b4b8a8ade7bc66255bd3c",
      "80daec702664419abd36664f63d7922e",
      "78f64286512243429d02e27a7401a9d4",
      "bd957bde44f24cd2abe2efe70d57202c",
      "2c61a9980e884b7e802ed5a88fe328bf",
      "6a3f7eb9e12542bea167d02cc6b98e06",
      "54a77f40b5c345df93f9c9ef704e462d",
      "18c9f9d081c0405eb26bc48629be5741",
      "a4bd55073bfa45418673df09651f8f2b",
      "33cb395854314d0ebdc04bdff01a01fc",
      "c0c0c858c4c346688b2a15caa370ddda",
      "34b5ab65968b4f1680423ff9d7ef94ee",
      "f89f338bc6634bff8f7f344180927e69",
      "e1f9c8ad72b84bbd93b4ca8544a14c8e",
      "f53fc7f615654f68a83c9a80c367e81d",
      "e543e9a6c86e45dba1544e2322ae1044",
      "efeb7a92035f479280687d3bfa1bc60e",
      "5257540494924527910acc093030a30a",
      "1f9f061ff77a4df4ae8abc1adf0e9841",
      "29077d24dd77414db6aa2def10e0a28f",
      "cb0ebe8fe04d451296c0b769dc758c73",
      "ceb5c52d6ebb4cc3bcace08c7ac0bd15",
      "185cb3ed91604a4f8170e586d78e1107",
      "9fd2628a4c574ed8a3660cf6ff31e06b",
      "9e618ee7448449129af3db6e1cc5569e",
      "d78362e4203046c1964d1a8489994db9",
      "0a2a3e9a31fc4218b68137d642b65cbd",
      "a357b83ce5884b1cb2c791b80f3c7710",
      "63b202068f664f04bb8285f32ee98c98",
      "b73de482b33d404f805483283540bad9",
      "bdc2faefb2f647aa8af993d06588e13f",
      "127568f7ffe64225b67de24f99d3f71a",
      "737c539734784c94b96523cbb943bb20",
      "64e8e0b46c564ad59ab73d56eecb01d2",
      "e178d5d8cf124559afa182ef83b5ad1c",
      "cacf12ff5dc6430dac94b5bea24a1331",
      "e08c7e8a15644b0d9882eb15a24b726e"
     ]
    },
    "outputId": "9732fff6-81de-4eef-b0b3-e02aefa9840e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.11.6: Fast Llama patching. Transformers: 4.57.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c58c2843648b482698ed0eeac728de72"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b57bae2a8a4f4abf9512c5c60f876f85"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e037c4882c6a4a07be2ce6fcbeaa5a57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c61a9980e884b7e802ed5a88fe328bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e543e9a6c86e45dba1544e2322ae1044"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a2a3e9a31fc4218b68137d642b65cbd"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we'll use the get_peft_model from unsloth's FastLanguageModel class to attach adapters (peft layers) on top of the models in order to perform QLoRA"
   ],
   "metadata": {
    "id": "3uQafcIi1-AZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16, # a higher alpha value assigns more weight to the LoRA activations\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc139iO81_e5",
    "outputId": "66657574-11da-4544-c798-5b2af2f0cb06"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth 2025.11.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"lewtun/drug-reviews\", split=\"train\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "f5b1c7303d784d84adf35d329dd3a1e3",
      "4bd805479da34738b6c52397a3520d91",
      "1fbd8a952f1148d0b505cc4e429f846b",
      "4f2251b3a40d4c61a162865622a19a54",
      "aea713fbe8444240abbe4703a3fc4e68",
      "0b2c199025b84eb799e3810ef6d3a04b",
      "07e5b1762aeb48cb91f66f307d2d5273",
      "1db7843d96fb4f2ea73f0cbc75ebbcc2",
      "33db55ddb5fa4bbcbb0ea162310618f0",
      "591471c74a7240efaf3b6eb57bdb72a6",
      "9391f7d007d5430c9b8a0d6cc0a83d4f",
      "7498573422d04d30ae68d85fb7f647b2",
      "f45b12ef1c7449c08ee6d2d2c667c2e4",
      "af6dddb598014b338bafdd010583b1d6",
      "3c8ca7fe946c48f09558136998bae9e6",
      "e146fcb7a64a4fb7aed5d5bb36db5b81",
      "440a6d5f3aaa4160b37454eb5ae9aedb",
      "a20d84f75c2d47138c21adb9c8988247",
      "49b7055d8ea842b3abd09abbf3d7f7d9",
      "7a515504348e4a369df5262b3b5e6758",
      "4a4740190fe14de2aeaecf4f7eb09bfc",
      "152cb825e6c942eaa3590adc263e8074",
      "e921e085b8c84aceb947991418a2ecb8",
      "50adedf7e2ef4ad49ef93967233dd2f8",
      "38c891df45ee4b089d972e55fa2164f2",
      "5971861599ca4d7ba502cbb113fbf31f",
      "6c503e6c8f5748c6bec19b0fd35c88d4",
      "5e1dc2671b8d40498c11740d3359dc24",
      "2cfa6cfa791a46169befcd7d31efa372",
      "287f6981ebe74b1e91c4ecb63c85762f",
      "aed59502f9a04399b5048557174ca5e6",
      "ad3ed9f0706241eeace1d79fb9585a15",
      "dff43ad62c92403aa1de18e09110ac8c",
      "6108c617765b4df6b361644f8e0977b4",
      "2f0103ba82ac47ed8e2936e3b5f37534",
      "94131bc6e1224d28aa84c756e5227c12",
      "35c094309a3a4bc685a04af30f7d756a",
      "58617275ca1c4374a3bbe1b13e74d2fe",
      "7e2b96090c57415ba71ac40794f03cc4",
      "882274dd09874b1090647516d191e494",
      "2953c36cd67e414d81b577ebd3be2152",
      "b7d062b79d2d4230bc8c2e780987c770",
      "36d5cf118e374c9d98f08bdde5f97e2c",
      "f8ccdd1a967a4407a55256072848c198"
     ]
    },
    "id": "5WknY2ZqCX8B",
    "outputId": "db7dd77b-551b-41fa-f4d4-13dc57e8ab82"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "train.jsonl:   0%|          | 0.00/97.7M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5b1c7303d784d84adf35d329dd3a1e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "test.jsonl:   0%|          | 0.00/32.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7498573422d04d30ae68d85fb7f647b2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e921e085b8c84aceb947991418a2ecb8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/53766 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6108c617765b4df6b361644f8e0977b4"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(dataset[:10])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyalThD-DODO",
    "outputId": "08fc9537-0606-4fcd-f13b-14a30badb0b7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Unnamed: 0': [206461, 95260, 92703, 138000, 35696, 155963, 165907, 102654, 74811, 48928], 'drugName': ['Valsartan', 'Guanfacine', 'Lybrel', 'Ortho Evra', 'Buprenorphine / naloxone', 'Cialis', 'Levonorgestrel', 'Aripiprazole', 'Keppra', 'Ethinyl estradiol / levonorgestrel'], 'condition': ['Left Ventricular Dysfunction', 'ADHD', 'Birth Control', 'Birth Control', 'Opiate Dependence', 'Benign Prostatic Hyperplasia', 'Emergency Contraception', 'Bipolar Disorde', 'Epilepsy', 'Birth Control'], 'review': ['\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"', '\"My son is halfway through his fourth week of Intuniv. We became concerned when he began this last week, when he started taking the highest dose he will be on. For two days, he could hardly get out of bed, was very cranky, and slept for nearly 8 hours on a drive home from school vacation (very unusual for him.) I called his doctor on Monday morning and she said to stick it out a few days. See how he did at school, and with getting up in the morning. The last two days have been problem free. He is MUCH more agreeable than ever. He is less emotional (a good thing), less cranky. He is remembering all the things he should. Overall his behavior is better. \\r\\nWe have tried many different medications and so far this is the most effective.\"', '\"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects. But it contained hormone gestodene, which is not available in US, so I switched to Lybrel, because the ingredients are similar. When my other pills ended, I started Lybrel immediately, on my first day of period, as the instructions said. And the period lasted for two weeks. When taking the second pack- same two weeks. And now, with third pack things got even worse- my third period lasted for two weeks and now it&#039;s the end of the third week- I still have daily brown discharge.\\r\\nThe positive side is that I didn&#039;t have any other side effects. The idea of being period free was so tempting... Alas.\"', '\"This is my first time using any form of birth control. I&#039;m glad I went with the patch, I have been on it for 8 months. At first It decreased my libido but that subsided. The only downside is that it made my periods longer (5-6 days to be exact) I used to only have periods for 3-4 days max also made my cramps intense for the first two days of my period, I never had cramps before using birth control. Other than that in happy with the patch\"', '\"Suboxone has completely turned my life around.  I feel healthier, I&#039;m excelling at my job and I always have money in my pocket and my savings account.  I had none of those before Suboxone and spent years abusing oxycontin.  My paycheck was already spent by the time I got it and I started resorting to scheming and stealing to fund my addiction.  All that is history.  If you&#039;re ready to stop, there&#039;s a good chance that suboxone will put you on the path of great life again.  I have found the side-effects to be minimal compared to oxycontin.  I&#039;m actually sleeping better.   Slight constipation is about it for me.  It truly is amazing. The cost pales in comparison to what I spent on oxycontin.\"', '\"2nd day on 5mg started to work with rock hard erections however experianced headache, lower bowel preassure. 3rd day erections would wake me up &amp; hurt! Leg/ankles aches   severe lower bowel preassure like you need to go #2 but can&#039;t! Enjoyed the initial rockhard erections but not at these side effects or $230 for months supply! I&#039;m 50 &amp; work out 3Xs a week. Not worth side effects!\"', '\"He pulled out, but he cummed a bit in me. I took the Plan B 26 hours later, and took a pregnancy test two weeks later - - I&#039;m pregnant.\"', '\"Abilify changed my life. There is hope. I was on Zoloft and Clonidine when I first started Abilify at the age of 15.. Zoloft for depression and Clondine to manage my complete rage. My moods were out of control. I was depressed and hopeless one second and then mean, irrational, and full of rage the next. My Dr. prescribed me 2mg of Abilify and from that point on I feel like I have been cured though I know I&#039;m not.. Bi-polar disorder is a constant battle. I know Abilify works for me because I have tried to get off it and lost complete control over my emotions. Went back on it and I was golden again.  I am on 5mg 2x daily. I am now 21 and better than I have ever been in the past. Only side effect is I like to eat a lot.\"', '\" I Ve had  nothing but problems with the Keppera : constant shaking in my arms &amp; legs &amp; pins &amp; needles feeling in my arms &amp; legs severe light headedness no appetite &amp; etc.\"', '\"I had been on the pill for many years. When my doctor changed my RX to chateal, it was as effective. It really did help me by completely clearing my acne, this takes about 6 months though. I did not gain extra weight, or develop any emotional health issues. I stopped taking it bc I started using a more natural method of birth control, but started to take it bc I hate that my acne came back at age 28. I really hope symptoms like depression, or weight gain do not begin to affect me as I am older now. I&#039;m also naturally moody, so this may worsen things. I was in a negative mental rut today. Also I hope this doesn&#039;t push me over the edge, as I believe I am depressed. Hopefully it&#039;ll be just like when I was younger.\"'], 'rating': [9.0, 8.0, 5.0, 8.0, 9.0, 2.0, 1.0, 10.0, 1.0, 8.0], 'date': ['May 20, 2012', 'April 27, 2010', 'December 14, 2009', 'November 3, 2015', 'November 27, 2016', 'November 28, 2015', 'March 7, 2017', 'March 14, 2015', 'August 9, 2016', 'December 8, 2016'], 'usefulCount': [27, 192, 17, 10, 37, 43, 5, 32, 11, 1]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "medical_prompt = \"\"\"\n",
    "Extract structured medical info from this patient review.\n",
    "\n",
    "medicine: {medicine}\n",
    "condition: {condition}\n",
    "rating: {rating}\n",
    "review: {review}\n",
    "\n",
    "Output MUST be in this format:\n",
    "\n",
    "medicine:\n",
    "side effect:\n",
    "condition:\n",
    "probability:\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    medicines = examples[\"drugName\"]\n",
    "    conditions = examples[\"condition\"]\n",
    "    reviews = examples[\"review\"]\n",
    "    ratings = examples[\"rating\"]\n",
    "\n",
    "    texts = []\n",
    "    for med, cond, rev, rate in zip(medicines, conditions, reviews, ratings):\n",
    "        text = medical_prompt.format(\n",
    "            medicine=med,\n",
    "            condition=cond,\n",
    "            rating=rate,\n",
    "            review=rev,\n",
    "        ) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d5daf3f2769047b79d3cb7705a668725",
      "6a73b0b860be4231bd33eb679c006097",
      "595151179fba414b87bcc0261389575a",
      "0640efa40f0b471b8be486404f3d89ac",
      "b12de4660d8e455e90adaf0725e86985",
      "5deb2149fa9d4851afba2e55c193a47d",
      "a92531b7ca064b6db7ced00652df445a",
      "a6c40bba0cf84e908404e03a5f65c854",
      "f6d0ec6d284c47d6bd21af485dea859c",
      "64b895f4c6474a79a5b139ba78e95db6",
      "d9dfc7fa009149e4ab58a1df7b47dabf"
     ]
    },
    "id": "EURyndGLDRhn",
    "outputId": "b9e69184-dc59-4666-a21a-ad9f21624b81"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5daf3f2769047b79d3cb7705a668725"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2, # Number of processors to use for processing the dataset\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2, # The batch size per GPU/TPU core\n",
    "        gradient_accumulation_steps = 4, # Number of steps to perform befor each gradient accumulation\n",
    "        warmup_steps = 5, # Few updates with low learning rate before actual training\n",
    "        max_steps = 60, # Specifies the total number of training steps (batches) to run.\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\", # Optimizer\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc for observability\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c51cd380d51f4dfca9f3022a3ccdf8b0",
      "779414f53a084e619f3274be50a1b3aa",
      "9f9e807e388d475b8bb1fda559ce2432",
      "be994a357076419d83ac8ce552d72223",
      "96255fb0837847629c47182395097524",
      "30921d5f4c00402098c23f85ea52bf8e",
      "a5f021eb390548478f59abc61f8693cb",
      "0e32a96bedac4480a8b3a6883125617b",
      "41bffd1c3c5449908098b98f405b37d4",
      "652df21471094b3eb400a9d7654eeaa9",
      "0821bb3febaf4b79a4583b937ca0ebe7"
     ]
    },
    "id": "yEo5pzzzYpr-",
    "outputId": "55ec47a2-2388-471e-9fa5-17e0dbfc097d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c51cd380d51f4dfca9f3022a3ccdf8b0"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_stats = trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ns_LaxTYZkja",
    "outputId": "78d2cae1-25bd-4282-a821-3a0f3a42ef06"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 161,297 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 02:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.196200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.910800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.830600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.879600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.875100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.849500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.846800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.877200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.541200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.778800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.781200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.667800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.825200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.700100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.575900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.854300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.829600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.909000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.826500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.737400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# 1. Update the tokenizer to use the Llama 3 format\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "# 2. Enable native 2x faster inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# 3. Define the \"Reasoning\" System Prompt (Personalized for your Medical Context)\n",
    "sys_prompt = \"\"\"You are a reflective medical assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before identifying potential side effects.\n",
    "<problem>\n",
    "{}\n",
    "</problem>\n",
    "\"\"\"\n",
    "\n",
    "# 4. Ask a question relevant to your dataset (Replacing the \"Strawberry\" example)\n",
    "# Example: Asking about a drug from your dataset\n",
    "user_question = \"What are the common side effects of taking Sronyx?\"\n",
    "\n",
    "message = sys_prompt.format(user_question)\n",
    "\n",
    "# 5. Format the message for the model\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": message},\n",
    "]\n",
    "\n",
    "# 6. Tokenize the input\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 7. Generate the output\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs,\n",
    "    max_new_tokens = 1024,\n",
    "    use_cache = True,\n",
    "    temperature = 1.5,\n",
    "    min_p = 0.1\n",
    ")\n",
    "\n",
    "# 8. Decode and print the result\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "print(response[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkgSsqtYaHB_",
    "outputId": "6727aac0-8f9a-464f-dfac-40f75521a6eb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You are a reflective medical assistant engaging in thorough, iterative reasoning, mimicking human stream-of-consciousness thinking. Your approach emphasizes exploration, self-doubt, and continuous refinement before identifying potential side effects.\n",
      "<problem>\n",
      "What are the common side effects of taking Sronyx?\n",
      "</problem>\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "assistant.trainableOUTPUT Generation Output\n",
      "must take at least 3 months to give its results.\n",
      "side effects are nausea, vomiting, pain, joint pain, muscle pain, weakness, and fever.\n",
      "<|eot_id|>\n"
     ]
    }
   ]
  }
 ]
}